{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Preprocesamiento**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pasos del preprocesamiento del texto de los subtítulos**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convertir las frases en minúsculas\n",
    "- Eliminar caracteres especiales y números presentes en el texto\n",
    "- Eliminar los espacios sobrantes\n",
    "- Eliminar caracteres sueltos\n",
    "- Añadir una etiqueta de inicio y otra de fin a las frases para indicar el principio y el final de una frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd # type: ignore\n",
    "from tqdm import tqdm # type: ignore\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array # type: ignore\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer # type: ignore\n",
    "from tensorflow.keras.applications import DenseNet201 # type: ignore\n",
    "from tensorflow.keras.models import Model # type: ignore\n",
    "\n",
    "image_path = '../../src/database/flickr8k/Images'\n",
    "captions_txt = '../../src/database/flickr8k/captions.txt'\n",
    "data = pd.read_csv('../../src/database/flickr8k/captions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\s'\n",
      "/tmp/ipykernel_53808/2714333614.py:4: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  data['caption'] = data['caption'].apply(lambda x: x.replace(\"\\s+\",\" \"))\n"
     ]
    }
   ],
   "source": [
    "def text_preprocessing(data):\n",
    "    data['caption'] = data['caption'].apply(lambda x: x.lower())\n",
    "    data['caption'] = data['caption'].apply(lambda x: x.replace(\"[^A-Za-z]\",\"\"))\n",
    "    data['caption'] = data['caption'].apply(lambda x: x.replace(\"\\s+\",\" \"))\n",
    "    data['caption'] = data['caption'].apply(lambda x: \" \".join([word for word in x.split() if len(word)>1]))\n",
    "    data['caption'] = \"startseq \"+data['caption']+\" endseq\"\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['startseq child in pink dress is climbing up set of stairs in an entry way endseq',\n",
       " 'startseq girl going into wooden building endseq',\n",
       " 'startseq little girl climbing into wooden playhouse endseq',\n",
       " 'startseq little girl climbing the stairs to her playhouse endseq',\n",
       " 'startseq little girl in pink dress going into wooden cabin endseq',\n",
       " 'startseq black dog and spotted dog are fighting endseq',\n",
       " 'startseq black dog and tri-colored dog playing with each other on the road endseq',\n",
       " 'startseq black dog and white dog with brown spots are staring at each other in the street endseq',\n",
       " 'startseq two dogs of different breeds looking at each other on the road endseq',\n",
       " 'startseq two dogs on pavement moving toward each other endseq']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = text_preprocessing(data)\n",
    "captions = data['caption'].tolist()\n",
    "captions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tokenización y representación codificada**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Las palabras de una frase se separan/tokenizan y se codifican en una representación en caliente.\n",
    "- Estas codificaciones se pasan a la capa de incrustación para generar incrustaciones de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 18, 315, 63, 195, 116, 2]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(captions)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "max_length = max(len(caption.split()) for caption in captions)\n",
    "\n",
    "images = data['image'].unique().tolist()\n",
    "nimages = len(images)\n",
    "\n",
    "split_index = round(0.85*nimages)\n",
    "train_images = images[:split_index]\n",
    "val_images = images[split_index:]\n",
    "\n",
    "train = data[data['image'].isin(train_images)]\n",
    "test = data[data['image'].isin(val_images)]\n",
    "\n",
    "train.reset_index(inplace=True,drop=True)\n",
    "test.reset_index(inplace=True,drop=True)\n",
    "\n",
    "tokenizer.texts_to_sequences([captions[1]])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Extracción de características de la imagen**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se utiliza la arquitectura DenseNet 201 para extraer las características de las imágenes\n",
    "- También se puede utilizar cualquier otra arquitectura preentrenada para extraer características de estas imágenes.\n",
    "- Dado que se ha seleccionado la capa Global Average Pooling como capa final del modelo DenseNet201 para la extracción de características, las imágenes incrustadas serán un vector de tamaño 1920"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 20:55:16.194663: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels.h5\n",
      "\u001b[1m82524592/82524592\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8091/8091 [17:21<00:00,  7.77it/s]\n"
     ]
    }
   ],
   "source": [
    "model = DenseNet201()\n",
    "fe = Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "\n",
    "img_size = 224\n",
    "features = {}\n",
    "for image in tqdm(data['image'].unique().tolist()):\n",
    "    img = load_img(os.path.join(image_path,image),target_size=(img_size,img_size))\n",
    "    img = img_to_array(img)\n",
    "    img = img/255.\n",
    "    img = np.expand_dims(img,axis=0)\n",
    "    feature = fe.predict(img, verbose=0)\n",
    "    features[image] = feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Guardar preprocesamientos**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('../../src/database/flickr8k/captions_preprocessed.txt', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = '../../src/database/flickr8k/images_features.json'\n",
    "features = {k: v.tolist() for k, v in features.items()}\n",
    "with open(output_file, 'w') as json_file:\n",
    "    json.dump(features, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
